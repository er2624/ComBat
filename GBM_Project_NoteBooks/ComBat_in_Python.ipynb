{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Please see README for details regarding ComBat algorithm in general, where this code came from, and\n",
    "#its uses and limitations.\n",
    "\n",
    "#Please refer to sample runs for concrete examples of how each piece affects the normalization \n",
    "#(e.g., a case with no numerical covariates vs. one with, etc.).\n",
    "\n",
    "#What follows are the essential pieces of the code to run the algorithm in python. \n",
    "#Resulting dataframe is identical for all values to dataframe produced in R using same same initial\n",
    "#data (up to 1e(-5))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Packages/modules necessary\n",
    "import pandas as pd\n",
    "import numpy.linalg as la\n",
    "import numpy as np\n",
    "import patsy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The following are functions that run within ComBat - each is briefly explained. \n",
    "#For details, see README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Design matrix based on identified batches and numerical covariates.\n",
    "def design_mat(mod, numerical_covariates, batch_levels):\n",
    "    # require levels to make sure they are in the same order as we use in the\n",
    "    # rest of the script.\n",
    "    design = patsy.dmatrix(\"~ 0 + C(batch, levels=%s)\" % str(batch_levels),\n",
    "                                                  mod, return_type=\"dataframe\")\n",
    "\n",
    "    mod = mod.drop([\"batch\"], axis=1)\n",
    "    numerical_covariates = list(numerical_covariates)\n",
    "    sys.stderr.write(\"found %i batches\\n\" % design.shape[1])\n",
    "    other_cols = [c for i, c in enumerate(mod.columns)\n",
    "                  if not i in numerical_covariates]\n",
    "    factor_matrix = mod[other_cols]\n",
    "    design = pd.concat((design, factor_matrix), axis=1)\n",
    "    if numerical_covariates is not None:\n",
    "        sys.stderr.write(\"found %i numerical covariates...\\n\"\n",
    "                            % len(numerical_covariates))\n",
    "        for i, nC in enumerate(numerical_covariates):\n",
    "            cname = mod.columns[nC]\n",
    "            sys.stderr.write(\"\\t{0}\\n\".format(cname))\n",
    "            design[cname] = mod[mod.columns[nC]]\n",
    "    sys.stderr.write(\"found %i categorical variables:\" % len(other_cols))\n",
    "    sys.stderr.write(\"\\t\" + \", \".join(other_cols) + '\\n')\n",
    "    return design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameter used in delta_star calculation.\n",
    "def aprior(gamma_hat):\n",
    "    m = gamma_hat.mean()\n",
    "    s2 = gamma_hat.var()\n",
    "    return (2 * s2 +m**2) / np.float64(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameter used in delta_star calculation.\n",
    "def bprior(gamma_hat):\n",
    "    m = gamma_hat.mean()\n",
    "    s2 = gamma_hat.var()\n",
    "    return (m*s2+m**3) / np.float64(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Used to calculate gamma_star - appears in it_sol and it_sol_loc functions.\n",
    "def postmean(g_hat, g_bar, n, d_star, t2):\n",
    "    return (t2*n*g_hat+d_star * g_bar) / (t2*n+d_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Used to calculated delta_star - appears in it_sol and it_sol_scale functions.\n",
    "def postvar(sum2, n, a, b):\n",
    "    return (0.5 * sum2 + b) / (n / 2.0 + a - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If mean_only = False, used to generate gamma_star and delta_star\n",
    "def it_sol(sdat, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001):\n",
    "    n = (1 - np.isnan(sdat)).sum(axis=1)\n",
    "    g_old = g_hat.copy()\n",
    "    d_old = d_hat.copy()\n",
    "\n",
    "    change = 1\n",
    "    count = 0\n",
    "    while change > conv:\n",
    "        #print g_hat.shape, g_bar.shape, t2.shape\n",
    "        g_new = postmean(g_hat, g_bar, n, d_old, t2)\n",
    "        sum2 = ((sdat - np.dot(g_new.reshape((g_new.shape[0], 1)), np.ones((1, sdat.shape[1])))) ** 2).sum(axis=1)\n",
    "        d_new = postvar(sum2, n, a, b)\n",
    "       \n",
    "        change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max())\n",
    "        g_old = g_new #.copy()\n",
    "        d_old = d_new #.copy()\n",
    "        count = count + 1\n",
    "    adjust = (g_new, d_new)\n",
    "    return adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If mean_only = True, used to generate gamma_star only\n",
    "def it_sol_loc(g_hat, g_bar, n, d_hat, t2):\n",
    "    n = 1\n",
    "    g_old = g_hat.copy()\n",
    "    d_old = d_hat.copy()\n",
    "\n",
    "    g_new = postmean(g_hat, g_bar, n, d_old, t2)\n",
    "    g_old = g_new #.copy()\n",
    "    adjust = (g_new)\n",
    "    return adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#If mean_only = True, used to generate delta_star only\n",
    "def it_sol_scale(sdat, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001):\n",
    "    n = (1 - np.isnan(sdat)).sum(axis=1)\n",
    "    g_old = g_hat.copy()\n",
    "    d_old = d_hat.copy()\n",
    "\n",
    "    change = 1\n",
    "    count = 0\n",
    "    while change > conv:\n",
    "        #print g_hat.shape, g_bar.shape, t2.shape\n",
    "        g_new = postmean(g_hat, g_bar, n, d_old, t2)\n",
    "        sum2 = ((sdat - np.dot(g_new.reshape((g_new.shape[0], 1)), np.ones((1, sdat.shape[1])))) ** 2).sum(axis=1)\n",
    "        d_new = postvar(sum2, n, a, b)\n",
    "       \n",
    "        change = (abs(d_new - d_old) / d_old).max()\n",
    "        g_old = g_new #.copy()\n",
    "        d_old = d_new #.copy()\n",
    "        count = count + 1\n",
    "    adjust = (d_new, g_new)\n",
    "    return adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The following is the actual ComBat function itself - each major section is briefly explained.\n",
    "#See README for further details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def combat(data, batch, model=None, numerical_covariates=None, mean_only=False, ref_batch=None):\n",
    "    \"\"\"Correct for batch effects in a dataset\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        A (n_features, n_samples) dataframe of the expression to batch correct\n",
    "    batch : List-like\n",
    "        A column corresponding to the batches in the data, in the same order\n",
    "        as the samples in ``data``\n",
    "    model : patsy.design_info.DesignMatrix, optional\n",
    "        A model matrix describing metadata on the samples which could be\n",
    "        causing batch effects. If not provided, then will attempt to coarsely\n",
    "        correct just from the information provided in ``batch``\n",
    "    numerical_covariates : list-like\n",
    "        List of covariates in the model which are numerical, rather than\n",
    "        categorical\n",
    "    mean_only : (T/F)\n",
    "        Only adjusts for mean across the batches, forgoing scale (variance) adjustment. \n",
    "        Default = False\n",
    "    ref_batch : int\n",
    "        Adjusts all batches to the specified referance batch. Specified batch will not be adjusted.\n",
    "        Default = None\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    corrected : pandas.DataFrame\n",
    "        A (n_features, n_samples) dataframe of the batch-corrected data\n",
    "    \"\"\"\n",
    "    #If designating numerical_covariates, this is the first point of incorporaiton.\n",
    "    if isinstance(numerical_covariates, str):\n",
    "        numerical_covariates = [numerical_covariates]\n",
    "    \n",
    "    if numerical_covariates is None:\n",
    "        numerical_covariates = []\n",
    "\n",
    "    if model is not None and isinstance(model, pd.DataFrame):\n",
    "        model[\"batch\"] = list(batch)\n",
    "    \n",
    "    else:\n",
    "        model = pd.DataFrame({'batch': batch})\n",
    "        \n",
    "    #If using ref_batch, this is the first point of incorporation.\n",
    "    if ref_batch is not None and isinstance(ref_batch, int):\n",
    "        ref = int(ref_batch)\n",
    "\n",
    "    batch_items = model.groupby(\"batch\").groups.items()\n",
    "    batch_levels = [k for k, v in batch_items]\n",
    "    batch_info = [v for k, v in batch_items]\n",
    "    n_batch = len(batch_info)\n",
    "    n_batches = np.array([len(v) for v in batch_info])\n",
    "    n_array = sum(n_batches)\n",
    "    \n",
    "    #Drop intercept\n",
    "    drop_cols = [cname for cname, inter in  ((model == 1).all()).iteritems() if inter == True]\n",
    "    drop_idxs = [list(model.columns).index(cdrop) for cdrop in drop_cols]\n",
    "    model = model[[c for c in model.columns if not c in drop_cols]]\n",
    "    numerical_covariates = [list(model.columns).index(c) if isinstance(c, str) else c\n",
    "            for c in numerical_covariates if not c in drop_cols]\n",
    "    \n",
    "    #Creation of design matrix from design_mat function defined above\n",
    "    design = design_mat(model, numerical_covariates, batch_levels)\n",
    "    \n",
    "    #If ref_batch designated, replaces 0s with 1s for all values in that column.\n",
    "    if ref_batch is not None:\n",
    "        design.iloc[:,ref-1] = 1.\n",
    "    \n",
    "    #Standardizes the data across genes.\n",
    "    sys.stderr.write(\"Standardizing Data across genes.\\n\")\n",
    "    B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T)\n",
    "    \n",
    "    #grand_mean and var_pooled calculated, depending on presence/absence of ref_batch designation.\n",
    "    \n",
    "    #NOTE: if using ref_batch, 'dft' (DataFrameTranspose) will be very important - it refers to \n",
    "    #whatever array contains your batch designating column, as well as any other columns specifying \n",
    "    #covariates. For example, in the bladderbatch data, this would be the array typically labeled\n",
    "    #'pheno'.\n",
    "    #The code below is set up for a dataframe that contains cell lines as index, \n",
    "    #gene names as columns, and a final column that contains batch number - thus making it easier\n",
    "    # to pull out the cell lines and associated genetic info by batch. This is NOT the case\n",
    "    #for something like the pheno' dataframe, which contains info corresponding to a seperate dataframe\n",
    "    #that actually has the genetic data.\n",
    "    #Depending on the way the 'dft' array is initially set up, an additional line of code and naming\n",
    "    #modification may need to be added to line up the arrays, but it has purposly been kept as a \n",
    "    #simple, single extra line - see worked bladderbatch example with refbatch2.\n",
    "    if ref_batch is not None:\n",
    "        grand_mean = B_hat[ref-1]\n",
    "        refdat = dft.loc[dft['batch'] == ref].drop('batch', axis=1)\n",
    "        reflist=refdat.index.tolist()\n",
    "        desbatch=design.T[reflist].T\n",
    "        var_pooled = np.dot(((refdat - np.dot(desbatch, B_hat))**2).T, np.ones((n_batches[ref-1], 1)) / n_batches[ref-1])\n",
    "            \n",
    "    else:\n",
    "        grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch,:])\n",
    "        var_pooled = np.dot(((data - np.dot(design, B_hat).T)**2), np.ones((n_array, 1)) / n_array)\n",
    "\n",
    "    stand_mean = np.dot(grand_mean.T.reshape((len(grand_mean), 1)), np.ones((1, n_array)))\n",
    "    tmp = np.array(design.copy())\n",
    "    tmp[:,:n_batch] = 0\n",
    "    stand_mean  += np.dot(tmp, B_hat).T\n",
    "    \n",
    "    #Standardized dataframe obtained.\n",
    "    s_data = ((data - stand_mean) / np.dot(np.sqrt(var_pooled), np.ones((1, n_array))))\n",
    "\n",
    "    #Get regression parameters - first point of mean_only argument incorporation.\n",
    "    sys.stderr.write(\"Fitting L/S model and finding priors\\n\")\n",
    "    batch_design = design[design.columns[:n_batch]]\n",
    "    gamma_hat = np.dot(np.dot(la.inv(np.dot(batch_design.T, batch_design)), batch_design.T), s_data.T)\n",
    "\n",
    "    #If mean_only = True, all delta_hat values set to 1.\n",
    "    delta_hat = []\n",
    "\n",
    "    for i, batch_idxs in enumerate(batch_info):\n",
    "        if mean_only is False:\n",
    "            delta_hat.append(s_data[batch_idxs].var(axis=1))\n",
    "        \n",
    "        else:\n",
    "            x=s_data[batch_idxs].var(axis=1)\n",
    "            x[x<100]=1\n",
    "            np.float64(delta_hat.append(x))\n",
    "            \n",
    "    gamma_bar = gamma_hat.mean(axis=1) \n",
    "    t2 = gamma_hat.var(axis=1)\n",
    "    \n",
    "    #aprior and bprior functions defined above - create hyperparameters to be used in delta_star.\n",
    "    a_prior = list(map(aprior, delta_hat))\n",
    "    b_prior = list(map(bprior, delta_hat))\n",
    "    \n",
    "    sys.stderr.write(\"Finding parametric adjustments\\n\")\n",
    "    \n",
    "    #If adjusting for both location (mean) and scale (variance), will use it_sol function defined\n",
    "    #above to generate gamma_star and delta_star for subsequent adjustment.\n",
    "    \n",
    "    #If mean_only = True, it_sol_loc function defined above will be used for gamma_star, and \n",
    "    #it_sol_scale will be used to first generate delta_star, and then delta_star \n",
    "    #values will be replaced by 1s.\n",
    "    \n",
    "    gamma_star, delta_star = [], []\n",
    "    for i, batch_idxs in enumerate(batch_info):\n",
    "    \n",
    "        if mean_only is False:\n",
    "            \n",
    "            temp = it_sol(s_data[batch_idxs], gamma_hat[i],\n",
    "            delta_hat[i], gamma_bar[i], t2[i], a_prior[i], b_prior[i])\n",
    "\n",
    "            gamma_star.append(temp[0])\n",
    "            delta_star.append(temp[1])\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            temploc = it_sol_loc(gamma_hat[i], gamma_bar[i], 1, delta_hat[i], t2[i])\n",
    "\n",
    "            gamma_star.append(temploc)\n",
    "        \n",
    "            tempscale = it_sol_scale(s_data[batch_idxs], gamma_hat[i],\n",
    "                     delta_hat[i], gamma_bar[i], t2[i], a_prior[i], b_prior[i])\n",
    "        \n",
    "            y=tempscale[1]\n",
    "            y[y<100]=1\n",
    "            delta_star.append(y)\n",
    "    \n",
    "    #Normalize the data, depending on mean_only and ref_batch arguments incorporated above.\n",
    "    sys.stdout.write(\"Adjusting data\\n\")\n",
    "    bayesdata = s_data\n",
    "    gamma_star = np.array(gamma_star)\n",
    "    delta_star = np.array(delta_star)\n",
    "    \n",
    "    #Ensures ref_batch corresponding values are not adjusted.  \n",
    "    if ref_batch is not None:\n",
    "        gamma_star[ref-1]=0\n",
    "        delta_star[ref-1]=1\n",
    "\n",
    "    for j, batch_idxs in enumerate(batch_info):\n",
    "\n",
    "        dsq = np.sqrt(delta_star[j,:])\n",
    "        dsq = dsq.reshape((len(dsq), 1))\n",
    "        denom =  np.dot(dsq, np.ones((1, n_batches[j])))\n",
    "        numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.ix[batch_idxs], gamma_star).T)\n",
    "\n",
    "        bayesdata[batch_idxs] = numer / denom\n",
    "   \n",
    "    vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1))\n",
    "    bayesdata = bayesdata * np.dot(vpsq, np.ones((1, n_array))) + stand_mean\n",
    "   \n",
    "    return bayesdata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
